{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# API Cost and Token Length Analysis\n",
    "\n",
    "This notebook analyses the expected token usage and estimated costs of API-based\n",
    "annotation (tokenization, lemmatization, and POS tagging) for the French medical\n",
    "AOI texts used in the thesis.\n",
    "\n",
    "It provides:\n",
    "- descriptive statistics about AOI lengths,\n",
    "- visualisation of their distribution,\n",
    "- identification of the longest AOIs (worst-case prompt sizes),\n",
    "- and token-based cost estimation for GPT-4o and GPT-4o-mini models.\n",
    "\n",
    "These calculations informed the batching and budgeting strategy for the annotation\n",
    "runs described in Section 3.5.1 of the thesis.\n"
   ],
   "id": "e4c797b7376cb40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup: Imports and Dependencies\n",
    "\n",
    "Import libraries for data handling, analysis, visualization, and API tokenization cost estimation."
   ],
   "id": "58d0c2d0a76927ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken"
   ],
   "id": "c55d5a8d9b9f5208"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Load AOI dictionary\n",
    "\n",
    "**Input**\n",
    "`aoi_tuples_dict.json`\n",
    "Generated previously in `00_annotation_preprocessing.ipynb`.\n",
    "Contains AOI sentence groups with `id_aoi_tuples` (lists of `(AOI_ID, word)` pairs).\n",
    "\n",
    "**Process**\n",
    "Loads the JSON dictionary and counts the number of AOI sentence entries to verify input integrity.\n",
    "\n",
    "**Output**\n",
    "- In-memory `sentence_dict` (Python dictionary)\n",
    "- Printed number of sentences for reference\n"
   ],
   "id": "f40f0be0f3f379c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"aoi_tuples_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentence_dict = json.load(f)\n",
    "\n",
    "num_sentences = len(sentence_dict)\n",
    "print(f\"Number of sentences: {num_sentences}\")\n"
   ],
   "id": "3903911c9f5b35d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Compute AOI length statistics\n",
    "\n",
    "**Input**\n",
    "`sentence_dict` loaded in Step 1.\n",
    "\n",
    "**Process**\n",
    "For each AOI group, counts the number of `id_aoi_tuples` entries to determine:\n",
    "- average AOI length,\n",
    "- minimum and maximum AOI length.\n",
    "\n",
    "**Output**\n",
    "Console summary:\n"
   ],
   "id": "dbde0b3c48b36c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_entries_list = [len(v[\"id_aoi_tuples\"]) for v in sentence_dict.values()]\n",
    "average_entries = np.mean(num_entries_list)\n",
    "max_entries = np.max(num_entries_list)\n",
    "min_entries = np.min(num_entries_list)\n",
    "\n",
    "print(f\"Average entries per AOI: {average_entries:.2f}\")\n",
    "print(f\"Maximum entries: {max_entries}\")\n",
    "print(f\"Minimum entries: {min_entries}\")\n"
   ],
   "id": "d5b263d3db4f1623"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Identify longest AOIs\n",
    "\n",
    "**Input**\n",
    "`sentence_dict`\n",
    "\n",
    "**Process**\n",
    "Uses a heap-based ranking to extract the ten AOIs with the highest number of words (`id_aoi_tuples`).\n",
    "This identifies potential outliers and large prompts that may exceed model limits.\n",
    "\n",
    "**Output**\n",
    "Console output listing the top 10 longest AOI entries and their lengths.\n"
   ],
   "id": "8a3cad72e37f8bba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "top_longest = heapq.nlargest(\n",
    "    10, [(len(v[\"id_aoi_tuples\"]), k) for k, v in sentence_dict.items()]\n",
    ")\n",
    "\n",
    "print(\"Top 10 longest AOIs:\")\n",
    "for length, key in top_longest:\n",
    "    print(f\"{key}: {length} entries\")\n"
   ],
   "id": "6904ff1f2349e346"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Visualize AOI length distribution\n",
    "\n",
    "**Input**\n",
    "`sentence_dict`\n",
    "\n",
    "**Process**\n",
    "Plots a histogram showing the distribution of AOI lengths (number of word entries per sentence).\n",
    "This helps determine whether the AOI set is balanced or if some entries are unusually long.\n",
    "\n",
    "**Output**\n",
    "Matplotlib histogram with labeled axes:\n",
    "- X-axis: “Number of AOI entries”\n",
    "- Y-axis: “Frequency”\n"
   ],
   "id": "2831d2e8234ac3b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_sentence_length_histogram(sentence_dict):\n",
    "    \"\"\"\n",
    "    Plot histogram of the number of AOI entries per text segment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence_dict : dict\n",
    "        Dictionary mapping text IDs to AOI-entry lists.\n",
    "    \"\"\"\n",
    "    lengths = [len(v[\"id_aoi_tuples\"]) for v in sentence_dict.values()]\n",
    "    plt.hist(lengths, bins=\"auto\", color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(\"Distribution of AOI Lengths\")\n",
    "    plt.xlabel(\"Number of AOI entries\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(axis=\"y\", alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "generate_sentence_length_histogram(sentence_dict)\n"
   ],
   "id": "7d491256e2ca6333"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Estimate API token usage and cost\n",
    "\n",
    "**Input**\n",
    "Representative prompt–response pair (copied from test annotations).\n",
    "Model rates for GPT-4o and GPT-4o-mini.\n",
    "\n",
    "**Process**\n",
    "- Encodes input and output strings using `tiktoken` to simulate real API tokenization.\n",
    "- Calculates approximate costs per request given OpenAI’s published rates.\n",
    "- Allows toggling between models to compare pricing.\n",
    "\n",
    "**Output**\n",
    "Console output summarizing:\n"
   ],
   "id": "67126b99f3a7ffc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example prompt/response pair\n",
    "example_prompt = \"\"\"...\"\"\"\n",
    "example_response = \"\"\"...\"\"\"\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "input_tokens = len(enc.encode(example_prompt))\n",
    "output_tokens = len(enc.encode(example_response))\n",
    "\n",
    "# Pricing (USD per 1M tokens)\n",
    "RATES = {\n",
    "    \"gpt-4o\": {\"in\": 2.5, \"out\": 10},\n",
    "    \"gpt-4o-mini\": {\"in\": 0.15, \"out\": 0.6},\n",
    "}\n",
    "\n",
    "model = \"gpt-4o\"  # or \"gpt-4o-mini\"\n",
    "input_cost = (input_tokens / 1e6) * RATES[model][\"in\"]\n",
    "output_cost = (output_tokens / 1e6) * RATES[model][\"out\"]\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(\n",
    "    f\"Model: {model}\\n\"\n",
    "    f\"Input tokens: {input_tokens}\\n\"\n",
    "    f\"Output tokens: {output_tokens}\\n\"\n",
    "    f\"Estimated cost: ${total_cost:.4f}\"\n",
    ")\n"
   ],
   "id": "cdfc46b9828bfeb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 6: Interpretation\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "The histogram above shows the typical AOI segment lengths used for API annotation.\n",
    "The token and cost analysis provides an upper bound for processing expenses.\n",
    "In the production annotation pipeline (see `01_api_annotation_pipeline.ipynb`),\n",
    "AOIs were batched to remain below the tested token limit and expected cost per run.\n",
    "\n",
    "Our results indicated that using GPT-4o we would pay less than 4\\\\$ for the entire\n",
    "dataset, including lemmatization and POS tagging, while GPT-4o-mini would cost less than 0.25\\\\$.\n"
   ],
   "id": "edd8edeaf636c1f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7044ca0b45d838ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
